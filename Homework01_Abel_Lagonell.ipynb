{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eef79ccf-fa57-482a-8564-784e8994bc2b",
   "metadata": {},
   "source": [
    "# Question 1: Discretization\n",
    "\n",
    "The categories:\n",
    "- Cold     :        x <  70\n",
    "- Warm     : 70  <= x <= 85\n",
    "- Hot      : 85  <  x <  100\n",
    "- Very Hot : 100 <= x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da793c29-bb68-493d-a4a3-6eb276762911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    data     label\n",
      "0     72      Warm\n",
      "1     85      Warm\n",
      "2     90       Hot\n",
      "3     77      Warm\n",
      "4     65      Cold\n",
      "5     80      Warm\n",
      "6     95       Hot\n",
      "7    102  Very Hot\n",
      "8     60      Cold\n",
      "9     68      Cold\n",
      "10    88       Hot\n",
      "11    73      Warm\n",
      "12    78      Warm\n",
      "13    69      Cold\n",
      "14    91       Hot\n",
      "15   -10      Cold\n",
      "16    -5      Cold\n",
      "17   -20      Cold\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "temperature = pd.DataFrame({ 'data' : [72, 85, 90, 77, 65, 80, 95, 102, 60, 68, 88, 73, 78, 69, 91, -10, -5, -20]})\n",
    "\n",
    "temperature['label'] = pd.cut(temperature.data, bins=[-float('inf'),70,85,100,float('inf')], labels=[\"Cold\", \"Warm\", \"Hot\", \"Very Hot\"])\n",
    "\n",
    "print(temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7dd20b-ba64-411c-b0a5-5970f1c5ccb3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "The code reflects the categories as everything is correctly categorized, with the bins being (-inf,70], (70,85],  (85,100], and (100, inf). With these bins nothing had to be changed to reflect the dataset given with the categories given.\n",
    "\n",
    "# Question 2: Numeric Coding of Nominal/Ordinal Attributes\n",
    "\n",
    "## Task 2.A: One-Hot Encoding Using OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "604ef7dc-e61a-42f5-8ef1-a251b32d4e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alago\\AppData\\Local\\Temp\\ipykernel_10348\\321458631.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     data    0    1    2    3\n",
      "0  Toyota  0.0  0.0  0.0  1.0\n",
      "1    Ford  0.0  1.0  0.0  0.0\n",
      "2   Honda  0.0  0.0  1.0  0.0\n",
      "3  Toyota  0.0  0.0  0.0  1.0\n",
      "4     BMW  1.0  0.0  0.0  0.0\n",
      "5    Ford  0.0  1.0  0.0  0.0\n",
      "6   Honda  0.0  0.0  1.0  0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "car_brands = pd.DataFrame({ 'data' : [\"Toyota\", \"Ford\", \"Honda\", \"Toyota\", \"BMW\", \"Ford\", \"Honda\"]})\n",
    "\n",
    "hot = pp.OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "hot_brands = pd.DataFrame(hot.fit_transform(car_brands).toarray())\n",
    "\n",
    "final_brands = car_brands.join(hot_brands)\n",
    "\n",
    "print(final_brands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd72b90-6760-453c-8909-ec3623cfb121",
   "metadata": {},
   "source": [
    "The categories are as follows Toyota = 3, Honda = 2, Ford = 1, BMW= 0.  \n",
    "The columns right of the data are categorizing the data into one of the four categories.\n",
    "\n",
    "## Task 2.B Ordinal Encoding Using OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb71fb90-60b9-4728-be9c-b981dadd0728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alago\\AppData\\Local\\Temp\\ipykernel_14272\\1411083497.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Brand Size    0    1\n",
      "0  Toyota    M  3.0  1.0\n",
      "1    Ford    L  1.0  0.0\n",
      "2   Honda    S  2.0  2.0\n",
      "3  Toyota   XL  3.0  3.0\n",
      "4     BMW    M  0.0  1.0\n",
      "5    Ford    S  1.0  2.0\n",
      "6   Honda    L  2.0  0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "brand_size = pd.DataFrame({\n",
    "    'Brand': [\"Toyota\", \"Ford\", \"Honda\", \"Toyota\", \"BMW\", \"Ford\", \"Honda\"],\n",
    "    'Size': [\"M\", \"L\", \"S\", \"XL\", \"M\", \"S\", \"L\"]\n",
    "})\n",
    "\n",
    "ordinal = pp.OrdinalEncoder()\n",
    "\n",
    "enc_brand_size = pd.DataFrame(ordinal.fit_transform(brand_size))\n",
    "\n",
    "final_brand_size = brand_size.join(enc_brand_size)\n",
    "\n",
    "print(final_brand_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66880e26-2109-4430-af58-9cfd173da6e3",
   "metadata": {},
   "source": [
    "The way that numeric values are assigned are as follows\n",
    "| Numeric Value | Brand | Size |\n",
    "| ------------- | ----- | ---- |\n",
    "| 0             | BMW   | L    |\n",
    "| 1             | Ford  | M    |\n",
    "| 2             | Honda | S    |\n",
    "| 3             | Toyota| XL   |\n",
    "\n",
    "## Task 2.C Numeric Coding Using pandas' Factorize Function\n",
    "\n",
    "The Brands variable can be reused in this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "983a59e1-3156-4572-9507-016fcabe9f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 0 3 1 2] ['Toyota' 'Ford' 'Honda' 'BMW']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alago\\AppData\\Local\\Temp\\ipykernel_22992\\502101534.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "C:\\Users\\alago\\AppData\\Local\\Temp\\ipykernel_22992\\502101534.py:4: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  label, uniques = pd.factorize(['Toyota', 'Ford', 'Honda', 'Toyota', 'BMW', 'Ford', 'Honda'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "label, uniques = pd.factorize(['Toyota', 'Ford', 'Honda', 'Toyota', 'BMW', 'Ford', 'Honda'])\n",
    "\n",
    "print(label, uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c35dce-7cba-4760-9c59-2a36dbc840d2",
   "metadata": {},
   "source": [
    "The way that it is done is by order so since Toyota is first it gets assigned 0, and Ford being second will get 1, and so on.  \n",
    "The factorize method is simple because it makes sure that the numers are assigned in order, with scikit-learn it goes and labels them based on alphabetical order within the categories. LabelEncoder does it by the size of the brand so Toyota having the most letters the encoder gives it a label of 3.\n",
    "\n",
    "## Task 2.D One-Hot Encoding Using pandas' get_dummies Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "101c2948-2710-4528-b68b-e98e7f364f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data_BMW  data_Ford  data_Honda  data_Toyota\n",
      "0     False      False       False         True\n",
      "1     False       True       False        False\n",
      "2     False      False        True        False\n",
      "3     False      False       False         True\n",
      "4      True      False       False        False\n",
      "5     False       True       False        False\n",
      "6     False      False        True        False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alago\\AppData\\Local\\Temp\\ipykernel_24292\\3726889454.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "car_brands = pd.DataFrame({ 'data' : [\"Toyota\", \"Ford\", \"Honda\", \"Toyota\", \"BMW\", \"Ford\", \"Honda\"]})\n",
    "\n",
    "dummy = pd.get_dummies(car_brands)\n",
    "print(dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95f66c8-f7ce-4d9f-ad7a-87b2972c3d5c",
   "metadata": {},
   "source": [
    "One-Hot encoding is boolean values assigned to a 2D array which makes it fast for computers to just look up if the category was present in the index but it is the worst in terms of space since it needs an array the size of the number of categories times the number of indexes.\n",
    "\n",
    "# Question 3 Data Preprocessing and Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60cfbef2-7ffc-467b-a218-99fa57fc88d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomeID   Age   Income  Gender   JoinDate\n",
      "0        101  25.0  50000.0    Male 2022-01-15\n",
      "1        102  28.2  62000.0  Female 2022-01-22\n",
      "2        103  31.0  64600.0    Male 2022-01-15\n",
      "3        104  22.0  45000.0  Female 2022-01-22\n",
      "4        105  28.0  78000.0  Female 2022-01-22\n",
      "5        106  35.0  88000.0  Female 2022-01-25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "customers = pd.DataFrame({\n",
    "    'CustomeID' : [101, 102, 103, 104, 105, 106],\n",
    "    'Age' : [25, np.nan, 31,-22, 28, 35],\n",
    "    'Income': [50000, 62000, np.nan, 45000, 78000, 88000],\n",
    "    'Gender' : ['Male', 'Female', 'Male', np.nan, 'Female', 'F'],\n",
    "    'JoinDate' : ['2022-01-15', '2022/01/22', '15-01-2022', '2022-01-22', np.nan, '2022-01-25']\n",
    "})\n",
    "\n",
    "customers['Age'] = customers['Age'].abs()\n",
    "customers['Age'] = customers['Age'].fillna(customers['Age'].mean())\n",
    "\n",
    "customers['Income'] = customers['Income'].fillna(customers['Income'].mean())\n",
    "\n",
    "customers['JoinDate'] = pd.to_datetime(customers['JoinDate'], format='mixed')\n",
    "customers['JoinDate'] = customers['JoinDate'].fillna(customers['JoinDate'].median())\n",
    "\n",
    "customers['Gender'] = customers['Gender'].replace('F', 'Female')\n",
    "customers['Gender'] = customers['Gender'].fillna(customers['Gender'].mode().iloc[0])\n",
    "\n",
    "print(customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d12310-9077-4aed-af93-3988b6a2751a",
   "metadata": {},
   "source": [
    "For Age I just took the absolute value and took the mean as it is a good representation of the average age in the group.  \n",
    "For income I took the average to fill the NaN to make sure that the data is within the given data.  \n",
    "For Join Date I made sure that I had YYYY-MM-DD and for the NaN I made it the median as that was the easiest to insert into the data, the mean would have had to had more formatting done.\n",
    "For Gender I replaced F with Female first and then made the NaN into the most common to continue the trend.\n",
    "\n",
    "# Question 4: Feature  Selection\n",
    "\n",
    "## Task 4.A Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc25bdc-c2c4-4be1-8809-78476e475e57",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RFE\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_california_housing\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "\n",
    "california_housing = fetch_california_housing();\n",
    "housing_data = california_housing.data\n",
    "housing_target = california_housing.tar\n",
    "estimator = LinearRegression()\n",
    "selector = RFE(estimator, n_features_to_select=5, step=1)\n",
    "\n",
    "selector = selector.fit(housing_data, housing_target)\n",
    "X_selected = selector.transform(housing_data)\n",
    "\n",
    "selected_features = selector.support_\n",
    "feature_ranking = selector.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deb4aea-9f12-4178-be27-e70c76b4310e",
   "metadata": {},
   "source": [
    "# Question 5: Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bf9a692-9b12-4a12-ac97-173e58c9ca33",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame( {'HouseID': [1,2,3,4,5,6,7], 'LotSize': [400,16000,25000,36000,49000,64000,81000] })\n",
    "df.insert(2, 'LotSizeRoot', df['LotSize'].apply(lambda x: np.sqrt(x)), True)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel('House ID')\n",
    "\n",
    "ax1.set_ylabel('Lot Size')\n",
    "ax1.plot('HouseID', 'LotSize', data=df)\n",
    "ax1.tick_params(axis = 'y', labelcolor = 'blue')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Lot Size Root')\n",
    "ax2.plot('HouseID', 'LotSizeRoot', data=df, color='orange')\n",
    "ax2.tick_params(labelcolor = 'orange')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d356baf8-9d31-48b0-b485-4b8a369b4960",
   "metadata": {},
   "source": [
    "The Square Root transformation made it so that the data given follows a linear curve after the second house. With the unrooted data there is a curve and a more complicated formula is needed to make sure the data works well, as opposed to the rooted data there is more of a relationship between the house id and then lot size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
